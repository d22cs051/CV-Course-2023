# -*- coding: utf-8 -*-
"""D22CS051_Q6.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Y6M90Mbi3D8iD9_3UgNWjZiqGYhnduf9
"""

# importing libs
import cv2 as cv
from matplotlib import pyplot as plt
import numpy as np

# script to download data
import requests
import os

url = "https://github.com/myleott/mnist_png/raw/master/mnist_png.tar.gz"

res = requests.get(url)

if res.status_code == 200:
  print("Downloading... data")
  with open("mnist_png.tar.gz",'wb') as f:
    f.write(res.content)
  
  print("Downloading Done..., Starting extracting..")
  !tar -xf "mnist_png.tar.gz"
  print("Extraction Done!!!")
  print("Removing file mnist_png.tar.gz")
  os.remove("mnist_png.tar.gz")

# removing other folders then 0,1
!rm -rf mnist_png/*/[2-9]
print("Folder Removed 2-9 form both traning and testing!!!")

!rm -rf mnist_png/*/*/[0-9][0-9][0-9][0-9]*

from pathlib import Path

data_path = Path("mnist_png")
train_data_path = data_path / "training"
test_data_path = data_path / "testing"
train_data_path,test_data_path

train_data_images_list = list(train_data_path.glob("*/*.png"))
test_data_images_list = list(test_data_path.glob("*/*.png"))
print(f"total images in train_data_images: {len(train_data_images_list)},\n"
      f"total images in test_data_images: {len(test_data_images_list)}")

# reading images and normalizing
train_dataset = np.array([cv.imread(str(i),cv.IMREAD_GRAYSCALE)/255 for i in train_data_images_list])
train_dataset_label = np.array([str(i).split("/")[-2] for i in train_data_images_list])
test_dataset = np.array([cv.imread(str(i),cv.IMREAD_GRAYSCALE)/255 for i in test_data_images_list])
test_dataset_label = np.array([str(i).split("/")[-2] for i in test_data_images_list])
print(f"train dataset shape: {train_dataset.shape}, labels shape: {train_dataset_label.shape}")
print(f"test dataset shape: {test_dataset.shape}, labels shape: {test_dataset_label.shape}")

# vis. random samples
r,c = 3,3
random_idx = np.random.randint(0,train_dataset.shape[0],r*c)

plt.figure(figsize=(10,10))
for i in range(r*c):
  plt.subplot(r,c,i+1)
  plt.title(train_dataset_label[random_idx[i]])
  plt.imshow(train_dataset[random_idx[i]],cmap="gray")
  plt.axis("off")
plt.show()

# Drawing horizontal projection
random_idx = np.random.randint(0,train_dataset.shape[0])
img = train_dataset[random_idx]

# inverting image
_,img = cv.threshold(img, 0.5, 1, cv.THRESH_BINARY)

plt.subplot(1,2,1)
plt.imshow(img,cmap="gray")

plt.subplot(1,2,2)
# Calculate horizontal projection
h_proj = np.sum(img,1)

# Create output image same height as input
height, width = np.max(h_proj),img.shape[1]
result = np.zeros((h_proj.shape[0],28),dtype=np.uint8)
# Draw a line for each row
for row in range(img.shape[0]):
  cv.line(result, (0,row), (int(h_proj[row]*width/height),row), (255,255), 1)
plt.imshow(result,cmap="gray")

plt.show()

def make_h_proj_dataset(dataset):
  res_dataset = []
  for i in range(len(dataset)):
    img = train_dataset[i]

    # inverting image
    _,img = cv.threshold(img, 0.5, 1, cv.THRESH_BINARY)

    # Calculate horizontal projection
    h_proj = np.sum(img,1)

    # Create output image same height as input
    height, width = np.max(h_proj),img.shape[1]
    result = np.zeros((h_proj.shape[0],28),dtype=np.uint8)
    # Draw a line for each row
    for row in range(img.shape[0]):
      cv.line(result, (0,row), (int(h_proj[row]*width/height),row), (255,255), 1)
    res_dataset.append(result)
  return np.array(res_dataset)

h_proj_train_dataset = make_h_proj_dataset(train_dataset)
h_proj_test_dataset = make_h_proj_dataset(test_dataset)
# NOTE:- the labels will remain the same

print(f"train dataset shape: {h_proj_train_dataset.shape}, labels shape: {train_dataset_label.shape}")
print(f"test dataset shape: {h_proj_test_dataset.shape}, labels shape: {test_dataset_label.shape}")

# vis. random samples from projection dataset
r,c = 3,3
random_idx = np.random.randint(0,h_proj_train_dataset.shape[0],r*c)

plt.figure(figsize=(10,10))
for i in range(r*c):
  plt.subplot(r,c,i+1)
  plt.title(train_dataset_label[random_idx[i]])
  plt.imshow(h_proj_train_dataset[random_idx[i]],cmap="gray")
  plt.axis("off")
plt.show()

# Classification With KNN
# training
from sklearn.neighbors import KNeighborsClassifier

X,y_train = h_proj_train_dataset,train_dataset_label

nsamples, nx, ny = X.shape
X_train = X.reshape((nsamples,nx*ny))

clf_knn = KNeighborsClassifier(n_neighbors=3)
clf_knn.fit(X_train, y_train)
clf_knn

# testing
X_test,y_test = h_proj_test_dataset,test_dataset_label

nsamples, nx, ny = X_test.shape
X_test = X_test.reshape((nsamples,nx*ny))

y_preds =  clf_knn.predict(X_test)

acc = np.sum(y_preds==y_test)/len(y_test)
print(f"Acc. with knn n_neighbors=3, is: {acc*100:.2f}%")

# Classification With SVM
# training
from sklearn import svm, metrics

X,y_train = h_proj_train_dataset,train_dataset_label

nsamples, nx, ny = X.shape
X_train = X.reshape((nsamples,-1))
# print(X_train.shape)

clf_svm = svm.SVC(gamma=0.01)
clf_svm.fit(X_train, y_train)
clf_svm

# testing
X_test,y_test = h_proj_test_dataset,test_dataset_label

nsamples, nx, ny = X_test.shape
X_test = X_test.reshape((nsamples,nx*ny))

y_preds =  clf_svm.predict(X_test)

acc = np.sum(y_preds==y_test)/len(y_test)
print(f"Acc. with svm gamma=0.01, is: {acc*100:.2f}%")